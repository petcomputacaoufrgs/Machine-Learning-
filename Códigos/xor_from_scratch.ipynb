{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse notebook, será construído uma rede neural a mão que consegue simular a porta lógica XOR, utilizando apenas a biblioteca NumPy. Enquanto os exemplos serão ilustrados considerando esse problema, essa mesma rede pode ser utilizado para resolver outros problemas mais complexos, como utilizada na [MNIST a mão](mnist_from_scratch.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def f(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    def f_prime(self, x):\n",
    "        return self.f(x) * (1-self.f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSELoss:\n",
    "    def f(self, y_hat, y):\n",
    "        return np.sum((y_hat - y)**2)/len(y_hat)\n",
    "    def f_prime(self, y_hat, y):\n",
    "        return 2*(y_hat - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagrama da rede e derivadas\n",
    "A rede possuí duas entradas e uma saída correspondentes a tabela-verdade do XOR. Nesse caso ela também possuirá uma hidden layer com dois neurônios.\n",
    "![Xor diagram](Imagens/xor_diagram_nn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, n_of_inputs: int, n_of_neurons: int , activation, bias: float=0.0):\n",
    "        self.n_of_inputs = n_of_inputs\n",
    "        self.n_of_neurons = n_of_neurons\n",
    "        self.activation = activation\n",
    "        self.bias = np.ones((1, n_of_neurons)) * bias # bias, inicializado como 0 por padrão\n",
    "        self.weights = np.random.uniform(-1, 1, (n_of_inputs, n_of_neurons)) # matriz de pesos \n",
    "        \n",
    "        # As variáveis abaixo são necessárias para o backward\n",
    "        self.weight_gradient = None  # vetor de gradiente dos pesos\n",
    "        self.bias_gradient = None # vetor de gradiente do bias\n",
    "        self.layer_inputs = None # output da camada anterior, ou as entradas da rede caso for a primeira camada\n",
    "        self.linear_output = None # resultado antes de ser aplicada a função de ativação -> linear_output = a @ w + b\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward propagation da camada\n",
    "        \"\"\"\n",
    "        # Shapes:\n",
    "        # Primeira para a segunda camada: (1, 2) @ (2, 2) = (1, 2)\n",
    "        # Segunda para a terceira camada: (1, 2) @ (2, 1) = (1, 1)\n",
    "        self.layer_inputs = x \n",
    "        dot_product = self.layer_inputs @ self.weights \n",
    "        self.linear_output = dot_product + self.bias\n",
    "        output = self.activation.f(self.linear_output)\n",
    "        return output\n",
    "\n",
    "    def backward(self, chain_rule_derivatives):\n",
    "        \"\"\"\n",
    "        Cálculo dos gradientes da camada. \n",
    "        É calculada as derivadas em relação a matriz de pesos e o bias da camada (dC_dw e dC_db), e a \n",
    "        derivada em relação ao linear_output (dC_da), para que possa mandar essa derivada para trás para calcular\n",
    "        o gradiente dos pesos das camadas anteriores, conforme o diagrama\n",
    "        Parâmetros:\n",
    "        chain_rule_derivatives - derivada calculada através da regra da cadeia, que foi mandada da camada seguinte (dC_da1)\n",
    "        Retorno:\n",
    "        updated_chain_rule_derivatives - derivada calculada através da regra da cadeia, para ser mandada para a camada anterior (dc_da0)\n",
    "        \"\"\"\n",
    "        da1_dz = self.activation.f_prime(self.linear_output) \n",
    "        dz_dw = self.layer_inputs\n",
    "        dz_da0 = self.weights\n",
    "        \n",
    "        dC_dw = dz_dw.T @ (da1_dz * chain_rule_derivatives) \n",
    "        dC_db = 1 * da1_dz * chain_rule_derivatives\n",
    "        dC_da0 = (chain_rule_derivatives * da1_dz) @ dz_da0.T\n",
    "        \n",
    "        updated_chain_rule_derivatives = dC_da0\n",
    "        self.weight_gradient = dC_dw\n",
    "        self.bias_gradient = dC_db\n",
    "        \n",
    "        return updated_chain_rule_derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classe Rede Neural\n",
    "Essa classe é a que será utilizada para construir o modelo. Utilizando a função *append layers* é possível adicionar quantas camadas que quiser à rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, lr):\n",
    "        self.layers = []\n",
    "        self.input_size = input_size\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward propagation da rede\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, loss_derivative):\n",
    "        \"\"\"\n",
    "        Backward propagation da rede.\n",
    "        Calcula os gradientes e aplica o algoritmo de gradiente descendente para atualizar os pesos e os bias\n",
    "        \"\"\"\n",
    "        # Cálculo dos gradientes\n",
    "        chain_rule_derivatives = loss_derivative\n",
    "        for layer in reversed(self.layers):\n",
    "            chain_rule_derivatives = layer.backward(chain_rule_derivatives)\n",
    "        \n",
    "        # Gradiente descendente\n",
    "        for layer in self.layers:\n",
    "            layer.weights -= layer.weight_gradient * self.lr\n",
    "            layer.bias -= layer.bias_gradient * self.lr\n",
    "\n",
    "    # Faz o forward chamando o objeto, passando os inputs como parâmetro, da mesma forma que o PyTorch faz\n",
    "    def __call__(self, inputs):\n",
    "        return self.forward(inputs)\n",
    "\n",
    "    def append_layer(self, output_number: int, activation, bias: float=0.0):\n",
    "        \"\"\"\n",
    "        Dado um número de saída, adiciona uma camada ao fim da rede neural\n",
    "        Ex: nn = NeuralNetwork(...)\n",
    "          nn.append_layer(...)\n",
    "          nn.append_layer(...)\n",
    "          ...\n",
    "        \"\"\"\n",
    "        # Caso seja a primeira camada\n",
    "        if len(self.layers) == 0:\n",
    "            new_layer_input = self.input_size\n",
    "        else:\n",
    "            new_layer_input = self.layers[-1].n_of_neurons\n",
    "\n",
    "        self.layers.append(Layer(new_layer_input, output_number, activation, bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela-verdade do XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uma dimensão extra é adicionada a cada combinação para ficar no formato (1, 2),\n",
    "# a fim de fazer as multiplicações de matrizes no forward\n",
    "X = np.array([[[0,0]], [[1, 0]], [[1, 1]], [[0, 1]]])\n",
    "y = np.array([0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os pesos são inicializados selecionando aleatoriamente em uma distribuição uniforme entre -1 e 1. Dessa forma, pode ser que seja necessário rodar mais de uma vez para obter uma loss perto de 0, caso aconteça de por chance ter uma inicialização que não favoreça o aprendizado do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 0.2\n",
    "criterion = MSELoss()\n",
    "losses = []\n",
    "nn = NeuralNetwork(2, lr)\n",
    "nn.append_layer(2, activation=Sigmoid())\n",
    "nn.append_layer(1, activation=Sigmoid())\n",
    "for epoch in range(5000):\n",
    "    total_loss = 0\n",
    "    for x, y0 in zip(X, y):\n",
    "        # Calcula a previsão\n",
    "        predicted = nn.forward(x)\n",
    "        # Computa a loss (float) e a derivada da loss (vetor)\n",
    "        loss = criterion.f(predicted, y0)\n",
    "        loss_derivative = criterion.f_prime(predicted, y0)\n",
    "        # Faz o backward da rede\n",
    "        nn.backward(loss_derivative)\n",
    "        total_loss += loss\n",
    "    losses.append(total_loss)\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inputs: np.array):\n",
    "    predicted = nn.forward(inputs)\n",
    "    print(f\"Entrada: {inputs[0][0]}, {inputs[0][1]}\\nXOR: {round(predicted[0][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada: 0, 0\n",
      "XOR: 0\n",
      "Entrada: 1, 0\n",
      "XOR: 1\n",
      "Entrada: 1, 1\n",
      "XOR: 0\n",
      "Entrada: 0, 1\n",
      "XOR: 1\n"
     ]
    }
   ],
   "source": [
    "for x in X:\n",
    "    predict(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}