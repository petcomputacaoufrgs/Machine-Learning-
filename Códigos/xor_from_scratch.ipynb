{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse notebook, será construído uma rede neural a mão que consegue simular a porta lógica XOR, utilizando apenas a biblioteca NumPy. Enquanto os exemplos serão ilustrados considerando esse problema, essa mesma rede pode ser utilizado para resolver outros problemas mais complexos, como utilizada na [MNIST a mão](mnist_from_scratch.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Function(ABC):\n",
    "    \"\"\"\n",
    "    Classe abstrata para as funções de ativação e de loss.\n",
    "    Exige que suas subclasses possuam uma função f e a derivada dessa função f_prime\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def f(self, *args):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def f_prime(self, *args):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Function):\n",
    "    def f(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    def f_prime(self, x):\n",
    "        return self.f(x) * (1-self.f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Function):\n",
    "    def f(self, x):\n",
    "        return (x > 0) * x\n",
    "    def f_prime(self, x):\n",
    "        return (x > 0) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSELoss(Function):\n",
    "    def f(self, y_hat, y):\n",
    "        return np.sum((y_hat - y)**2)/len(y_hat)\n",
    "    def f_prime(self, y_hat, y):\n",
    "        return 2*(y_hat - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagrama da rede e derivadas\n",
    "A rede possuí duas entradas e uma saída correspondentes a tabela-verdade do XOR. Nesse caso ela também possuirá uma hidden layer com dois neurônios.\n",
    "![Xor diagram](Imagens/xor_diagram_nn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, n_of_inputs: int, n_of_neurons: int , activation: Function, bias: float=0.0):\n",
    "        self.n_of_inputs = n_of_inputs\n",
    "        self.n_of_neurons = n_of_neurons\n",
    "        self.activation = activation\n",
    "        self.bias = np.ones((1, n_of_neurons)) * bias # bias, inicializado como 0 por padrão\n",
    "        self.weights = np.random.uniform(-1, 1, (n_of_inputs, n_of_neurons)) # matriz de pesos \n",
    "        \n",
    "        # As variáveis abaixo são necessárias para o backward\n",
    "        self.weight_gradient = None  # vetor de gradiente dos pesos\n",
    "        self.bias_gradient = None # vetor de gradiente do bias\n",
    "        self.layer_inputs = None # output da camada anterior, ou as entradas da rede caso for a primeira camada\n",
    "        self.linear_output = None # resultado antes de ser aplicada a função de ativação -> linear_output = a @ w + b\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward propagation da camada\n",
    "        \"\"\"\n",
    "        # Shapes:\n",
    "        # Primeira para a segunda camada: (1, 2) @ (2, 2) = (1, 2)\n",
    "        # Segunda para a terceira camada: (1, 2) @ (2, 1) = (1, 1)\n",
    "        self.layer_inputs = x \n",
    "        dot_product = self.layer_inputs @ self.weights \n",
    "        self.linear_output = dot_product + self.bias\n",
    "        output = self.activation.f(self.linear_output)\n",
    "        return output\n",
    "\n",
    "    def backward(self, chain_rule_derivatives):\n",
    "        \"\"\"\n",
    "        Cálculo dos gradientes da camada. \n",
    "        É calculada as derivadas em relação a matriz de pesos e o bias da camada (dC_dw e dC_db), e a \n",
    "        derivada em relação ao linear_output (dC_da), para que possa mandar essa derivada para trás para calcular\n",
    "        o gradiente dos pesos das camadas anteriores, conforme o diagrama\n",
    "        Parâmetros:\n",
    "        chain_rule_derivatives - derivada calculada através da regra da cadeia, que foi mandada da camada seguinte (dC_da1)\n",
    "        Retorno:\n",
    "        chain_rule_derivatives - derivada calculada através da regra da cadeia, para ser mandada para a camada anterior (dc_da0)\n",
    "        \"\"\"\n",
    "        da1_dz = self.activation.f_prime(self.linear_output) \n",
    "        dz_dw = self.layer_inputs\n",
    "        dz_da0 = self.weights\n",
    "        \n",
    "        dC_dw = dz_dw.T @ (da1_dz * chain_rule_derivatives) \n",
    "        dC_db = 1 * da1_dz * chain_rule_derivatives\n",
    "        dC_da0 = (chain_rule_derivatives * da1_dz) @ dz_da0.T\n",
    "        \n",
    "        chain_rule_derivatives = dC_da0\n",
    "        self.weight_gradient = dC_dw\n",
    "        self.bias_gradient = dC_db\n",
    "        \n",
    "        return chain_rule_derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, lr):\n",
    "        self.layers = []\n",
    "        self.input_size = input_size\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward propagation da rede\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, loss_derivative):\n",
    "        \"\"\"\n",
    "        Backward propagation da rede.\n",
    "        Calcula os gradientes e aplica o algoritmo de gradiente descendente para atualizar os pesos e os bias\n",
    "        \"\"\"\n",
    "        # Cálculo dos gradientes\n",
    "        chain_rule_derivatives = loss_derivative\n",
    "        for layer in reversed(self.layers):\n",
    "            chain_rule_derivatives = layer.backward(chain_rule_derivatives)\n",
    "        \n",
    "        # Gradiente descendente\n",
    "        for layer in self.layers:\n",
    "            layer.weights -= layer.weight_gradient * self.lr\n",
    "            layer.bias -= layer.bias_gradient * self.lr\n",
    "\n",
    "    # Faz o forward chamando o objeto, passando os inputs como parâmetro, da mesma forma que o PyTorch faz\n",
    "    def __call__(self, inputs):\n",
    "        return self.forward(inputs)\n",
    "\n",
    "    def append_layer(self, output_number: int, activation, bias: float=0.0):\n",
    "        \"\"\"\n",
    "        Dado um número de saída adiciona uma camada ao fim da rede neural\n",
    "        Ex: nn = NeuralNetwork(...)\n",
    "          nn.append_layer(...)\n",
    "          nn.append_layer(...)\n",
    "          ...\n",
    "        \"\"\"\n",
    "        # Caso seja a primeira camada\n",
    "        if len(self.layers) == 0:\n",
    "            new_layer_input = self.input_size\n",
    "        else:\n",
    "            new_layer_input = self.layers[-1].n_of_neurons\n",
    "\n",
    "        self.layers.append(Layer(new_layer_input, output_number, activation, bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabela-verdade do XOR\n",
    "X = np.array([[0,0], [1, 0], [1, 1], [0, 1]])\n",
    "y = np.array([0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0215\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = 0.3\n",
    "criterion = MSELoss()\n",
    "losses = []\n",
    "nn = NeuralNetwork(2, lr)\n",
    "nn.append_layer(2, activation=Sigmoid())\n",
    "nn.append_layer(1, activation=Sigmoid())\n",
    "'''\n",
    "Uma vez que os pesos são inicializados aleatoriamente entre -1 e 1, \n",
    "pode ser que seja necessário rodar mais de uma vez para obter uma loss perto de 0\n",
    "'''\n",
    "for epoch in range(1000):\n",
    "    total_loss = 0\n",
    "    for x, y0 in zip(X, y):\n",
    "        # Calcula a previsão\n",
    "        predicted = nn.forward(x.reshape(1,-1))\n",
    "        # Computa a loss (float) e a derivada da loss (vetor)\n",
    "        loss = criterion.f(predicted, y0)\n",
    "        loss_derivative = criterion.f_prime(predicted, y0)\n",
    "        # Faz o backward da rede\n",
    "        nn.backward(loss_derivative)\n",
    "        total_loss += loss\n",
    "    losses.append(total_loss)\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.show()\n",
    "print(f\"Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inputs: np.array):\n",
    "    predicted = nn.forward(inputs)\n",
    "    print(f\"Entrada: {inputs[0]}, {inputs[1]}\\nXOR: {round(predicted[0][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada: 0, 0\n",
      "XOR: 0\n",
      "Entrada: 1, 0\n",
      "XOR: 1\n",
      "Entrada: 1, 1\n",
      "XOR: 0\n",
      "Entrada: 0, 1\n",
      "XOR: 1\n"
     ]
    }
   ],
   "source": [
    "for x in X:\n",
    "    predict(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}